# Facial Emotion Recognition

<div id="top"></div>
<div align="center">

![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)
![TensorFlow](https://img.shields.io/badge/TensorFlow-%23FF6F00.svg?style=for-the-badge&logo=TensorFlow&logoColor=white)
![Jupyter Notebook](https://img.shields.io/badge/jupyter-%23FA0F00.svg?style=for-the-badge&logo=jupyter&logoColor=white)

</div>

<br />
<div align="center">
    <img src="assets/falcons-logo2.png" alt="Logo" >
</div>
<br /><br />
<div align="center">
    <img src="assets/dds_logo.png" alt="DDS logo" >
</div>
# Decoding Data Science in partnership with Falcons.ai
<br /><br />

Objective: Develop an efficient facial emotion classification system employing OpenCV/Tensorflow to identify facial emotions within video streams. The goal is to achieve a high level of accuracy, low latency, and minimal computational overhead.

Data Source: A video dataset or a combination of image datasets featuring the target objects in states of emotion.

Preprocessing (if needed): Standardize or augment the images/video frames to improve model generalization, if necessary, while preserving the aspect ratio and critical features.

Model Selection & Training:
1. Using the FER dataset(partial).
2. Train a custom model using the prepared dataset and analyze the performance.
3. Deploy Streamlit and OpenCV to allow users a web ui in which to upload a video and have the video frames analyzed by your model.

This problem set provides a clear path to address image analysis issues using OpenCV, with a focus on Facial Emotion Classification in video streams. It allows researchers or students to hone in on critical aspects such as data preprocessing, model selection, hyperparameter tuning, performance evaluation, and results interpretation.
    <br /><br /><br />




  </p>
  <br />
<p align="right">(<a href="#top">back to top</a>)</p>
<br />

<!-- How to use -->
## Usage
<br />
  <p>
   To use the notebook with relative ease please follow the steps below:
    <br />
</p>

1. Ensure all of the required libraries are installed.

2. Load the libraries.

3. Run the cells and the cloud images will be generated and saved in the "clouds" directory.

  </p>
  <br />
<p align="right">(<a href="#top">back to top</a>)</p>
<br />




<!-- CONTRIBUTING -->
## Contributing

Contributions are what make the open source community such an amazing place to learn, inspire, and create. Any contributions you make are **greatly appreciated**.

If you want, feel free to fork this repository. You can also simply open an issue with the tag "enhancement".
Don't forget to give the project a star! Thanks again!

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/YourFeature`)
3. Commit your Changes (`git commit -m 'Add some YourFeature'`)
4. Push to the Branch (`git push origin feature/YourFeature`)
5. Open a Pull Request
<br />
See the https://github.com/Falcons-ai/fer_dds_challenge/issues for a full list of proposed features (and known issues).

<p align="right">(<a href="#top">back to top</a>)</p>



<!-- LICENSE -->
## License

![](https://img.shields.io/badge/License-MIT-blue)

<p align="right">(<a href="#top">back to top</a>)</p>



<!-- CONTACT -->
## Contact

Project Link: [https://github.com/Falcons-ai/fer_dds_challenge]


<p align="right">(<a href="#top">back to top</a>)</p>
